###########################
# StackState HBase values #
###########################

# commonLabels -- Labels that will be applied to all resources created by this helm chart
commonLabels: {}
all:
  image:
    # all.image.registry -- Base container image registry for all containers, except for the wait container
    registry: quay.io
    # all.image.pullSecretName -- Name of ImagePullSecret to use for all pods.
    pullSecretName:
    # all.image.pullSecretUsername -- Username used to login to the registry to pull Docker images of all pods.
    pullSecretUsername:
    # all.image.pullSecretPassword -- Password used to login to the registry to pull Docker images of all pods.
    pullSecretPassword:
  extraEnv:
    # all.extraEnv.open -- Extra open environment variables to inject into pods for all components.
    open: {}
    # all.extraEnv.secret -- Extra secret environment variables to inject into pods via a `Secret` object for all components.
    secret: {}
  metrics:
    # all.metrics.enabled -- Enable metrics port.
    enabled: false
    # stackstate.components.all.metrics.agentAnnotationsEnabled -- Put annotations on each pod to instruct the stackstate agent to scrape the metrics
    agentAnnotationsEnabled: true
    servicemonitor:
      # all.metrics.servicemonitor.additionalLabels -- Additional labels for targeting Prometheus operator instances.
      additionalLabels: {}
      # all.metrics.servicemonitor.enabled -- Enable `ServiceMonitor` object; `all.metrics.enabled` *must* be enabled.
      enabled: false
  # all.nodeSelector -- Node labels for pod assignment on all components.
  nodeSelector: {}
  # all.tolerations -- Toleration labels for pod assignment on all components.
  tolerations: []
  # all.affinity -- Affinity settings for pod assignment on all components.
  affinity: {}
stackgraph:
  image:
    # stackgraph.image.pullPolicy -- The default pullPolicy used for all components of hbase that are stackgraph version dependent; invividual service `pullPolicy`s can be overriden (see below).
    pullPolicy: IfNotPresent
    # stackgraph.image.tag -- The default tag used for all omponents of hbase that are stackgraph version dependent; invividual service `tag`s can be overriden (see below).
    tag: 4.6.7
console:
  # console.enabled -- Enable / disable deployment of the stackgraph-console for debugging.
  enabled: true
  securityContext:
    # console.securityContext.enabled -- Whether to explicitly set the UID/GID of the pod.
    enabled: true
    # console.securityContext.runAsGroup -- GID of the Linux group to use for all pod.
    runAsGroup: 65534
    # console.securityContext.runAsUser -- UID of the Linux user to use for all pod.
    runAsUser: 65534
  extraEnv:
    # console.extraEnv.open -- Extra open environment variables to inject into pods.
    open: {}
    # console.extraEnv.secret -- Extra secret environment variables to inject into pods via a `Secret` object.
    secret: {}
  image:
    # console.image.pullPolicy -- Pull policy for console pods, defaults to `stackgraph.image.pullPolicy`
    pullPolicy:
    # console.image.repository -- Base container image repository for console pods.
    repository: stackstate/stackgraph-console
    # console.image.tag -- Container image tag for console pods, defaults to `stackgraph.image.tag`
    tag:
  # console.resources -- Resources to allocate for HDFS console.
  resources:
    limits:
      memory: "1Gi"
      cpu: "500m"
    requests:
      memory: "512Mi"
      cpu: "50m"
  # console.strategy -- The strategy for the Deployment object.
  strategy:
    type: RollingUpdate
    # rollingUpdate:
    #   maxUnavailable: 1
  # console.nodeSelector -- Node labels for pod assignment.
  nodeSelector: {}
  # console.tolerations -- Toleration labels for pod assignment.
  tolerations: []
  # console.affinity -- Affinity settings for pod assignment.
  affinity: {}
wait:
  image:
    # wait.image.registry -- Base container image registry for wait containers.
    registry: quay.io
    # wait.image.repository -- Base container image repository for wait containers.
    repository: stackstate/wait
    # wait.image.repository -- Container image tag for wait containers.
    tag: 1.0.6
    # wait.image.pullPolicy -- Image pull policy for wait containers.
    pullPolicy: IfNotPresent
hbase:
  securityContext:
    # hbase.securityContext.enabled -- Whether to explicitly set the UID/GID of the pod.
    enabled: true
    # hbase.securityContext.runAsGroup -- GID of the Linux group to use for all pod.
    runAsGroup: 65534
    # hbase.securityContext.runAsUser -- UID of the Linux user to use for all pod.
    runAsUser: 65534
  master:
    extraEnv:
      # hbase.master.extraEnv.open -- Extra open environment variables to inject into pods.
      open: {}
      # hbase.master.extraEnv.secret -- Extra secret environment variables to inject into pods via a `Secret` object.
      secret: {}
    image:
      # hbase.master.image.pullPolicy -- Pull policy for HBase masters, defaults to `stackgraph.image.pullPolicy`
      pullPolicy:
      # hbase.master.image.repository -- Base container image repository for HBase masters.
      repository: stackstate/hbase-master
      # hbase.master.image.tag -- Container image tag for HBase masters, defaults to `stackgraph.image.tag`
      tag:
    # hbase.master.replicaCount -- Number of pods for HBase masters.
    replicaCount: 1
    # hbase.master.resources -- Resources to allocate for HBase masters.
    resources:
      limits:
        memory: "1Gi"
      requests:
        memory: "1Gi"
        cpu: "50m"
    # hbase.master.nodeSelector -- Node labels for pod assignment.
    nodeSelector: {}
    # hbase.master.tolerations -- Toleration labels for pod assignment.
    tolerations: []
    # hbase.master.affinity -- Affinity settings for pod assignment.
    affinity: {}
  regionserver:
    extraEnv:
      # hbase.regionserver.extraEnv.open -- Extra open environment variables to inject into pods.
      open: {}
      # hbase.regionserver.extraEnv.secret -- Extra secret environment variables to inject into pods via a `Secret` object.
      secret: {}
    image:
      # hbase.regionserver.image.pullPolicy -- Pull policy for HBase region servers, defaults to `stackgraph.image.pullPolicy`
      pullPolicy:
      # hbase.regionserver.image.repository -- Base container image repository for HBase region servers.
      repository: stackstate/hbase-regionserver
      # hbase.regionserver.image.tag -- Container image tag for HBase region servers, defaults to `stackgraph.image.tag`
      tag:
    # hbase.regionserver.replicaCount -- Number of HBase regionserver nodes.
    replicaCount: 1
    # hbase.regionserver.resources -- Resources to allocate for HBase region servers.
    resources:
      limits:
        memory: "3Gi"
      requests:
        memory: "2Gi"
        cpu: "2000m"
    # hbase.regionserver.nodeSelector -- Node labels for pod assignment.
    nodeSelector: {}
    # hbase.regionserver.tolerations -- Toleration labels for pod assignment.
    tolerations: []
    # hbase.regionserver.affinity -- Affinity settings for pod assignment.
    affinity: {}
  zookeeper:
    # hbase.zookeeper.quorum -- Zookeeper quorum used for single-node Zookeeper installations; not used if `zookeeper.replicaCount` is more than `1`.
    quorum: hbase
hdfs:
  # hdfs.minReplication -- Sets the minimum synchronous replication that the namenode will enforce when writing a block. This gives guarantees about the amount of copies of a single block. (If hdfs.datanode.replicaCount is set to a value less than this, the replicationfactor will be equal to the replicaCount.)
  minReplication: 1
  scc:
    # hdfs.scc.enabled -- Whether to create an OpenShift SecurityContextConfiguration (required when running on OpenShift)
    enabled: false
  image:
    # hdfs.image.pullPolicy -- Pull policy for HDFS datanode.
    pullPolicy: IfNotPresent
    # hdfs.image.repository -- Base container image repository for HDFS datanode.
    repository: stackstate/hadoop
    # hdfs.image.tag -- Default container image tag for HDFS datanode.
    tag: 2.10.1-java11-6-2738734712
  volumePermissions:
    # hdfs.volumePermissions.enabled -- Whether to explicitly change the volume permissions for the data/name nodes. If permissions on volume mounts are not correct for whatever reason this can be used to set them properly. Usually also requires enabling the securityContext because root user is required.
    enabled: false
    securityContext:
      # hdfs.volumePermissions.securityContext.enabled -- Whether to add a securityContext to the volumePermissions init container
      enabled: false
      # hdfs.volumePermissions.securityContext.privileged -- Run the volumePermissions init container in privileged mode (required for plain K8s, not for OpenShift)
      privileged: true
      # hdfs.volumePermissions.securityContext.allowPrivilegeEscalation -- Run the volumePermissions init container with privilege escalation mode (Do not change unless instructed)
      allowPrivilegeEscalation: true
      # hdfs.volumePermissions.securityContext.runAsNonRoot -- Run the volumePermissions init container in non-root required mode (Do not change unless instructed)
      runAsNonRoot: false
      # hdfs.volumePermissions.securityContext.runAsUser -- Run the volumePermissions init container with the specified UID (Do not change unless instructed)
      runAsUser: 0
  securityContext:
    # hdfs.securityContext.enabled -- Whether to explicitly set the UID/GID of the pod.
    enabled: true
    # hdfs.securityContext.runAsGroup -- GID of the Linux group to use for all pod.
    runAsGroup: 65534
    # hdfs.securityContext.runAsUser -- UID of the Linux user to use for all pod.
    runAsUser: 65534
    fsGroup: 65534
  datanode:
    extraEnv:
      # hdfs.datanode.extraEnv.open -- Extra open environment variables to inject into pods.
      open: {}
      # hdfs.datanode.extraEnv.secret -- Extra secret environment variables to inject into pods via a `Secret` object.
      secret: {}
    persistence:
      # hdfs.datanode.persistence.accessModes -- Access mode for HDFS data nodes.
      accessModes: ["ReadWriteOnce"]
      # hdfs.datanode.persistence.enabled -- Enable persistence for HDFS data nodes.
      enabled: true
      # hdfs.datanode.persistence.size -- Size of volume for HDFS data nodes.
      size: 250Gi
      # hdfs.datanode.persistence.storageClass -- Storage class of the volume for HDFS data nodes.
      storageClass:
    # hdfs.datanode.replicaCount -- Number of HDFS data nodes.
    replicaCount: 1
    # hdfs.datanode.resources -- Resources to allocate for HDFS data nodes.
    resources:
      limits:
        memory: "4Gi"
      requests:
        memory: "2Gi"
        cpu: "50m"
    # hdfs.datanode.nodeSelector -- Node labels for pod assignment.
    nodeSelector: {}
    # hdfs.datanode.tolerations -- Toleration labels for pod assignment.
    tolerations: []
    # hdfs.datanode.terminationGracePeriodSeconds -- Grace period to stop the pod. We give some time to fix under replicated blocks in Pre Stop hook
    terminationGracePeriodSeconds: 600
    # hdfs.datanode.affinity -- Affinity settings for pod assignment.
    affinity: {}
  namenode:
    extraEnv:
      # hdfs.namenode.extraEnv.open -- Extra open environment variables to inject into pods.
      open: {}
      # hdfs.namenode.extraEnv.secret -- Extra secret environment variables to inject into pods via a `Secret` object.
      secret: {}
    persistence:
      # hdfs.namenode.persistence.accessModes -- Access mode for HDFS name nodes.
      accessModes: ["ReadWriteOnce"]
      # hdfs.namenode.persistence.enabled -- Enable persistence for HDFS name nodes.
      enabled: true
      # hdfs.namenode.persistence.size -- Size of volume for HDFS name nodes.
      size: 20Gi
      # hdfs.namenode.persistence.storageClass -- Storage class of the volume for HDFS name nodes.
      storageClass:
    # hdfs.namenode.resources -- Resources to allocate for HDFS name nodes.
    resources:
      limits:
        memory: "1Gi"
      requests:
        memory: "1Gi"
        cpu: "50m"
    # hdfs.namenode.nodeSelector -- Node labels for pod assignment.
    nodeSelector: {}
    # hdfs.namenode.tolerations -- Toleration labels for pod assignment.
    tolerations: []
    # hdfs.namenode.affinity -- Affinity settings for pod assignment.
    affinity: {}
  secondarynamenode:
    extraEnv:
      # hdfs.secondarynamenode.extraEnv.open -- Extra open environment variables to inject into pods.
      open: {}
      # hdfs.secondarynamenode.extraEnv.secret -- Extra secret environment variables to inject into pods via a `Secret` object.
      secret: {}
    # hdfs.secondarynamenode.enabled -- Enable / disable secondary name nodes.
    enabled: false
    persistence:
      # hdfs.secondarynamenode.persistence.accessModes -- Access mode for HDFS secondary name nodes.
      accessModes: ["ReadWriteOnce"]
      # hdfs.secondarynamenode.persistence.enabled -- Enable persistence for HDFS secondary name nodes.
      enabled: true
      # hdfs.secondarynamenode.persistence.size -- Size of volume for HDFS secondary name nodes.
      size: 20Gi
      # hdfs.secondarynamenode.persistence.storageClass -- Storage class of the volume for HDFS secondary name nodes.
      storageClass:
    # hdfs.secondarynamenode.resources -- Resources to allocate for HDFS secondary name nodes.
    resources:
      limits:
        memory: "1Gi"
      requests:
        memory: "1Gi"
        cpu: "50m"
    # hdfs.secondarynamenode.nodeSelector -- Node labels for pod assignment.
    nodeSelector: {}
    # hdfs.secondarynamenode.tolerations -- Toleration labels for pod assignment.
    tolerations: []
    # hdfs.secondarynamenode.affinity -- Affinity settings for pod assignment.
    affinity: {}
tephra:
  securityContext:
    # tephra.securityContext.enabled -- Whether to explicitly set the UID/GID of the pod.
    enabled: true
    # tephra.securityContext.runAsGroup -- GID of the Linux group to use for all pod.
    runAsGroup: 65534
    # tephra.securityContext.runAsUser -- UID of the Linux user to use for all pod.
    runAsUser: 65534
  extraEnv:
    # tephra.extraEnv.open -- Extra open environment variables to inject into pods.
    open: {}
    # tephra.extraEnv.secret -- Extra secret environment variables to inject into pods via a `Secret` object.
    secret: {}
  image:
    # tephra.image.pullPolicy -- Pull policy for Tephra pods, defaults to `stackgraph.image.pullPolicy`
    pullPolicy:
    # tephra.image.repository -- Base container image repository for Tephra pods.
    repository: stackstate/tephra-server
    # tephra.image.tag -- Container image tag for Tephra pods, defaults to `stackgraph.image.tag`
    tag:
  # tephra.replicaCount -- Number of pods for Tephra pods.
  replicaCount: 1
  # tephra.resources -- Resources to allocate for Tephra pods.
  resources:
    limits:
      memory: "3Gi"
    requests:
      memory: "2Gi"
      cpu: "50m"
  # tephra.nodeSelector -- Node labels for pod assignment.
  nodeSelector: {}
  # tephra.tolerations -- Toleration labels for pod assignment.
  tolerations: []
  # tephra.affinity -- Affinity settings for pod assignment.
  affinity: {}
serviceAccount:
  # serviceAccount.create -- Whether to create serviceAccounts and run the statefulsets under them
  create: true
##########################
# Common chart overrides #
##########################
statefulset:
  antiAffinity:
    # statefulset.antiAffinity.strategy -- AntiAffinity strategy to use for all StatefulSets.
    strategy: soft
    # statefulset.antiAffinity.topologyKey -- AntiAffinity topology key to use for all StatefulSets.
    topologyKey: kubernetes.io/hostname
#############################
# Zookeeper chart overrides #
#############################
zookeeper:
  # zookeeper.enabled -- Enable / disable chart-based Zookeeper.
  enabled: true
  # zookeeper.externalServers -- If `zookeeper.enabled` is set to `false`, use this list of external Zookeeper servers instead.
  externalServers: ""
  # zookeeper.fourlwCommandsWhitelist -- Zookeeper four-letter-word (FLW) commands that are enabled.
  fourlwCommandsWhitelist: "mntr, ruok, stat, srvr"
  metrics:
    # zookeeper.metrics.enabled -- Enable / disable Zookeeper Prometheus metrics.
    enabled: true
    serviceMonitor:
      # zookeeper.metrics.serviceMonitor.enabled -- Enable creation of `ServiceMonitor` objects for Prometheus operator.
      enabled: false
      # zookeeper.metrics.serviceMonitor.selector -- Default selector to use to target a certain Prometheus instance.
      selector:
        release: prometheus-operator
  # zookeeper.replicaCount -- Default amount of Zookeeper replicas to provision.
  replicaCount: 1
