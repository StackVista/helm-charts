{{- define "stackstate.problemProducer.deployment.container.init" -}}
name: server-init
command:
- sh
- -c
- |
  /entrypoint -c {{ include "stackstate.kafka.endpoint" . }},{{ include "stackstate.zookeeper.endpoint" . }},{{ .Release.Name }}-hbase-hdfs-nn-headful:9000,{{ template "common.fullname.short" . }}-initializer:1618 -t 300
image: "{{include "stackstate.wait.image.registry" .}}/{{ .Values.stackstate.components.wait.image.repository }}:{{ .Values.stackstate.components.wait.image.tag }}"
imagePullPolicy: {{ .Values.stackstate.components.wait.image.pullPolicy | quote }}
{{- end -}}

{{- define "stackstate.problemProducer.deployment.container.main" -}}
args:
{{- include "stackstate.service.args" . }}
- -startRole
- problemProducer
env:
{{- $serviceConfig := dict "ServiceName" "problem-producer" "ServiceConfig" .Values.stackstate.components.problemProducer }}
{{- include "stackstate.service.envvars" (merge $serviceConfig .) }}
{{- include "stackstate.authentication.envvars" . }}
{{- include "stackstate.baseurls.envvars" . }}
- name: API_KEY
  valueFrom:
    secretKeyRef:
      name: {{ template "common.fullname.short" . }}-receiver
      key: sts-receiver-api-key
- name: ELASTICSEARCH_URI
  value: "http://{{ include "stackstate.es.endpoint" . }}"
- name: KAFKA_BROKERS
  value: {{ include "stackstate.kafka.endpoint" . | quote }}
- name: HADOOP_USER_NAME
  value: nobody
- name: LICENSE_KEY
  valueFrom:
    secretKeyRef:
      name: {{ template "common.fullname.short" . }}-license
      key: sts-license-key
- name: ZOOKEEPER_QUORUM
  value: {{ include "stackstate.zookeeper.endpoint" . | quote }}
- name: CONFIG_FORCE_stackstate_stackPacks_localStackPacksUri
  value: "hdfs://{{ .Release.Name }}-hbase-hdfs-nn-headful:9000/stackpacks"
  # Keep data for a longlong time (a day), we actually want to run problem producer from cache
- name: CONFIG_FORCE_stackgraph_vertex_cache_expireAfterSeconds
  value: "86400"
image: "{{ include "stackstate.image.registry" . }}/{{ .Values.stackstate.components.problemProducer.image.repository }}{{ .Values.stackstate.components.all.image.repositorySuffix }}:{{ default .Values.stackstate.components.all.image.tag .Values.stackstate.components.problemProducer.image.tag }}"
imagePullPolicy: {{ default .Values.stackstate.components.all.image.pullPolicy .Values.stackstate.components.problemProducer.image.pullPolicy | quote }}
name: problem-producer
ports:
- containerPort: 1618
  name: health
- containerPort: 7080
  name: instance
{{- if .Values.stackstate.components.all.metrics.enabled }}
- containerPort: 9404
  name: metrics
{{- end }}
readinessProbe:
  httpGet:
    path: /readiness
    port: health
  initialDelaySeconds: 10
  timeoutSeconds: 5
livenessProbe:
  httpGet:
    path: /liveness
    port: health
  initialDelaySeconds: 60
  timeoutSeconds: 5
{{- with .Values.stackstate.components.problemProducer.resources }}
resources:
  {{- toYaml . | nindent 2 }}
{{- end }}
volumeMounts:
- name: config-secrets-volume
  mountPath: /opt/docker/etc/application_stackstate.conf
  subPath: application_stackstate.conf
{{- include "stackstate.service.container.volumes" . }}
{{- end -}}

{{- define "stackstate.problemProducer.deployment" -}}
{{- $commonContainer := fromYaml (include "common.container" .) -}}
{{- $overrideContainer := fromYaml (include "stackstate.problemProducer.deployment.container.main" .) -}}
{{- $stsStackstateProblemProducerMainContainer := (merge $overrideContainer $commonContainer) -}}
{{- $overrideContainer := fromYaml (include "stackstate.problemProducer.deployment.container.init" .) -}}
{{- $stsStackstateServerInitContainer := (merge $overrideContainer $commonContainer) -}}
{{- $overrideContainer := fromYaml (include "stackstate.initContainer.ensure.no.server.statefulset.pods.are.running" .) -}}
{{- $stsStackstateServerEnsureNoServerStatefulSetPodsAreRunningContainer := (merge $overrideContainer $commonContainer) -}}

metadata:
  name: {{ template "common.fullname.short" . }}-problem-producer
  labels:
    app.kubernetes.io/component: problem-producer
    stackstate.com/connects-to-stackgraph: "true"
    stackstate.com/replicas: "1"
spec:
  replicas: {{ .Values.stackstate.components.problemProducer.replicaCount }}
  selector:
    matchLabels:
      app.kubernetes.io/component: problem-producer
  strategy:
{{- if eq (lower .Values.stackstate.components.all.deploymentStrategy.type) "recreatesingletonsonly" }}
    type: Recreate
{{- else }}
    {{- toYaml .Values.stackstate.components.all.deploymentStrategy | nindent 4 }}
{{- end }}
  template:
    metadata:
      annotations:
        {{- include "common.metrics.annotations" (dict "metrics" .Values.stackstate.components.all.metrics "port" "9404" "container_name" "problem-producer" ) | indent 8 }}
        {{- include "stackstate.common.secret.checksum" . | nindent 8 }}
        {{- include "stackstate.license.secret.checksum" . | nindent 8 }}
        {{- include "stackstate.problemProducer.secret.checksum" . | nindent 8 }}
      labels:
        app.kubernetes.io/component: problem-producer
    spec:
      serviceAccountName: {{ template "common.fullname.short" . }}-problem-producer
      {{- include "stackstate.image.pullSecret.name" (dict "images" (list .Values.stackstate.components.all.image) "context" $) | nindent 6 }}
      initContainers:
      - {{ toYaml $stsStackstateServerInitContainer | nindent 8 }}
      - {{ toYaml $stsStackstateServerEnsureNoServerStatefulSetPodsAreRunningContainer | nindent 8 }}
      containers:
      - {{ toYaml $stsStackstateProblemProducerMainContainer | nindent 8 }}
    {{- if or .Values.stackstate.components.all.nodeSelector .Values.stackstate.components.state.nodeSelector }}
      nodeSelector:
      {{- with .Values.stackstate.components.all.nodeSelector }}
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.stackstate.components.problemProducer.nodeSelector }}
        {{- toYaml . | nindent 8 }}
      {{- end }}
    {{- end }}
    {{- if or .Values.stackstate.components.all.affinity .Values.stackstate.components.problemProducer.affinity }}
      affinity:
      {{- with .Values.stackstate.components.all.affinity }}
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.stackstate.components.problemProducer.affinity }}
        {{- toYaml . | nindent 8 }}
      {{- end }}
    {{- end }}
    {{- if or .Values.stackstate.components.all.tolerations .Values.stackstate.components.problemProducer.tolerations }}
      tolerations:
      {{- with .Values.stackstate.components.all.tolerations }}
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.stackstate.components.problemProducer.tolerations }}
        {{- toYaml . | nindent 8 }}
      {{- end }}
    {{- end }}
    {{- if .Values.stackstate.components.all.securityContext.enabled }}
      securityContext: {{- omit .Values.stackstate.components.all.securityContext "enabled" | toYaml | nindent 8 }}
    {{- end }}
      volumes:
        - name: config-secrets-volume
          secret:
            secretName: {{ template "common.fullname.short" . }}-problem-producer
        {{- include "stackstate.service.pod.volumes" (dict "pod_name" "problem-producer" "root" . ) | nindent 8 }}
{{- end -}}

{{- if .Values.stackstate.experimental.server.split }}
{{- $commonDeployment := fromYaml (include "common.deployment" .) -}}
{{- $problemProducerDeployment := fromYaml (include "stackstate.problemProducer.deployment" .) -}}
{{- toYaml (merge $problemProducerDeployment $commonDeployment) -}}
{{- end}}
